{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmr\\.conda\\envs\\class\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# pip install pymssql\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_csv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_csv == True:\n",
    "    df_sku = pd.read_csv('df_sku.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_csv == False:\n",
    "    sqluser = input('Enter SQL User')\n",
    "    sqlpass = input(f'Enter Password for {sqluser}')\n",
    "    ## instance a python db connection object- same form as psycopg2/python-mysql drivers also\n",
    "    conn = pymssql.connect(server=\"192.168.254.13\", user=sqluser,password=passwrd, port=1433)  # You can lookup the port number inside SQL server. \n",
    "\n",
    "    stmt = \"SELECT \\\n",
    "            SKU_ID \\\n",
    "            ,UOM_ID \\\n",
    "            ,SalesCategoryID \\\n",
    "            ,cat.CategoryID \\\n",
    "            ,NACSCategoryID \\\n",
    "            ,Category \\\n",
    "            ,Description \\\n",
    "            ,LongDescription \\\n",
    "            ,ShortDescription \\\n",
    "            ,POSDescription \\\n",
    "            FROM AgilityPB.dbo.tbl_SKU sku \\\n",
    "            left outer join Agility_Net.dbo.tbl_Categories cat on sku.SalesCategoryID = cat.CategoryID\"\n",
    "    # Excute Query here\n",
    "    df_sku = pd.read_sql(stmt,conn)\n",
    "    df_sku.to_csv('df_sku.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SKU_ID</th>\n",
       "      <th>UOM_ID</th>\n",
       "      <th>SalesCategoryID</th>\n",
       "      <th>CategoryID</th>\n",
       "      <th>NACSCategoryID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>LongDescription</th>\n",
       "      <th>ShortDescription</th>\n",
       "      <th>POSDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>General Merchandise</td>\n",
       "      <td>General Merchandise</td>\n",
       "      <td>1000 DRINKING GAMES IN A BOX</td>\n",
       "      <td>1000 DRINK GAME</td>\n",
       "      <td>1000 DRINKING GAMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>91</td>\n",
       "      <td>Salty Snacks</td>\n",
       "      <td>Salty Snacks Inv</td>\n",
       "      <td>2/$1 RED HOT SAUSAGE</td>\n",
       "      <td>MEAT SNACK RH</td>\n",
       "      <td>2/$1 RED HOT SAUSAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>91</td>\n",
       "      <td>Salty Snacks</td>\n",
       "      <td>Salty Snacks Inv</td>\n",
       "      <td>20 COUNT VARIETY PACK</td>\n",
       "      <td>VARIETY 20CT</td>\n",
       "      <td>20 COUNT VARIETY PACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>91</td>\n",
       "      <td>Salty Snacks</td>\n",
       "      <td>Salty Snacks Inv</td>\n",
       "      <td>26 CT 100 CALORIE VARIETY PACK</td>\n",
       "      <td>VARIETY 100CAL</td>\n",
       "      <td>26CT 100 CALORIE VARIETY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>91</td>\n",
       "      <td>Salty Snacks</td>\n",
       "      <td>Salty Snacks Inv</td>\n",
       "      <td>3 CHEESE MEDLEY NIBBLERS</td>\n",
       "      <td>PRETZEL 3 CHEESE</td>\n",
       "      <td>3 CHEESE MEDLEY NIBBLERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SKU_ID  UOM_ID  SalesCategoryID  CategoryID  NACSCategoryID  \\\n",
       "0           0       1     119               40          40             140   \n",
       "1           1       2     119               52          52              91   \n",
       "2           2       3     119               52          52              91   \n",
       "3           3       4     119               52          52              91   \n",
       "4           4       5     119               52          52              91   \n",
       "\n",
       "              Category          Description                 LongDescription  \\\n",
       "0  General Merchandise  General Merchandise    1000 DRINKING GAMES IN A BOX   \n",
       "1         Salty Snacks     Salty Snacks Inv            2/$1 RED HOT SAUSAGE   \n",
       "2         Salty Snacks     Salty Snacks Inv           20 COUNT VARIETY PACK   \n",
       "3         Salty Snacks     Salty Snacks Inv  26 CT 100 CALORIE VARIETY PACK   \n",
       "4         Salty Snacks     Salty Snacks Inv        3 CHEESE MEDLEY NIBBLERS   \n",
       "\n",
       "   ShortDescription            POSDescription  \n",
       "0   1000 DRINK GAME       1000 DRINKING GAMES  \n",
       "1     MEAT SNACK RH      2/$1 RED HOT SAUSAGE  \n",
       "2      VARIETY 20CT     20 COUNT VARIETY PACK  \n",
       "3    VARIETY 100CAL  26CT 100 CALORIE VARIETY  \n",
       "4  PRETZEL 3 CHEESE  3 CHEESE MEDLEY NIBBLERS  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sku.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_sku['LongDescription'], df_sku['Category'], train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes Classifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "          Alternative Snacks       0.88      0.82      0.85        73\n",
      "         Automotive Products       1.00      0.16      0.27        19\n",
      "                        Beer       0.96      0.95      0.96       160\n",
      "                       Candy       0.76      0.97      0.85       337\n",
      "                  Cigarettes       0.96      0.99      0.97        75\n",
      "    Cold Dispensed Beverages       0.00      0.00      0.00         4\n",
      "       Commissary - Packaged       1.00      0.58      0.74        36\n",
      "                E-Cigarettes       1.00      0.84      0.91        37\n",
      "              Edible Grocery       0.70      0.64      0.67       181\n",
      "         Fluid Milk Products       0.00      0.00      0.00         6\n",
      "                 Foodservice       0.00      0.00      0.00        15\n",
      "  Frozen Dispensed Beverages       0.00      0.00      0.00         3\n",
      "                Frozen Foods       0.00      0.00      0.00         1\n",
      "         General Merchandise       0.83      0.60      0.69       127\n",
      "           Health and Beauty       0.97      0.61      0.75       109\n",
      "     Hot Dispensed Beverages       0.00      0.00      0.00         1\n",
      "                         Ice       0.00      0.00      0.00         1\n",
      "                   Motor Oil       1.00      0.62      0.77        16\n",
      "    Non-edible Grocery NoTax       1.00      0.07      0.13        28\n",
      "          Other Dairy - Deli       0.00      0.00      0.00        12\n",
      "               Other Tobacco       0.87      0.97      0.92       189\n",
      "          Packaged Beverages       0.72      0.99      0.83       230\n",
      "Packaged Ice Cream Novelties       0.00      0.00      0.00         8\n",
      "       Packaged Sweet Snacks       0.89      0.70      0.78        96\n",
      "          Perishable Grocery       0.00      0.00      0.00         5\n",
      "                Publications       0.00      0.00      0.00         2\n",
      "                Salty Snacks       0.77      0.94      0.85       224\n",
      "                        Wine       1.00      0.28      0.43        18\n",
      "\n",
      "                    accuracy                           0.81      2013\n",
      "                   macro avg       0.55      0.42      0.44      2013\n",
      "                weighted avg       0.81      0.81      0.79      2013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmr\\.conda\\envs\\class\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-nearest Neighbor</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "          Alternative Snacks       0.74      0.99      0.85        73\n",
      "         Automotive Products       0.88      0.74      0.80        19\n",
      "                        Beer       0.93      0.94      0.93       160\n",
      "                       Candy       0.88      0.91      0.90       337\n",
      "                  Cigarettes       0.89      1.00      0.94        75\n",
      "    Cold Dispensed Beverages       0.75      0.75      0.75         4\n",
      "       Commissary - Packaged       0.82      0.89      0.85        36\n",
      "                E-Cigarettes       0.92      0.89      0.90        37\n",
      "              Edible Grocery       0.82      0.65      0.72       181\n",
      "         Fluid Milk Products       0.83      0.83      0.83         6\n",
      "                 Foodservice       0.58      0.47      0.52        15\n",
      "  Frozen Dispensed Beverages       1.00      0.33      0.50         3\n",
      "                Frozen Foods       1.00      1.00      1.00         1\n",
      "         General Merchandise       0.84      0.78      0.81       127\n",
      "           Health and Beauty       0.94      0.74      0.83       109\n",
      "     Hot Dispensed Beverages       0.00      0.00      0.00         1\n",
      "                         Ice       0.00      0.00      0.00         1\n",
      "                   Motor Oil       0.94      0.94      0.94        16\n",
      "    Non-edible Grocery NoTax       0.71      0.43      0.53        28\n",
      "          Other Dairy - Deli       0.75      0.25      0.38        12\n",
      "               Other Tobacco       0.92      0.95      0.94       189\n",
      "          Packaged Beverages       0.87      0.96      0.91       230\n",
      "Packaged Ice Cream Novelties       1.00      0.75      0.86         8\n",
      "       Packaged Sweet Snacks       0.85      0.86      0.86        96\n",
      "          Perishable Grocery       0.20      0.20      0.20         5\n",
      "                Publications       0.50      1.00      0.67         2\n",
      "                Salty Snacks       0.85      0.94      0.89       224\n",
      "                        Wine       0.92      0.61      0.73        18\n",
      "\n",
      "                    accuracy                           0.86      2013\n",
      "                   macro avg       0.76      0.71      0.72      2013\n",
      "                weighted avg       0.87      0.86      0.86      2013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmr\\.conda\\envs\\class\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Support Vector Machine (SVM)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "          Alternative Snacks       0.90      1.00      0.95        73\n",
      "         Automotive Products       1.00      0.74      0.85        19\n",
      "                        Beer       0.99      0.97      0.98       160\n",
      "                       Candy       0.95      0.96      0.96       337\n",
      "                  Cigarettes       1.00      1.00      1.00        75\n",
      "    Cold Dispensed Beverages       1.00      1.00      1.00         4\n",
      "       Commissary - Packaged       0.97      0.86      0.91        36\n",
      "                E-Cigarettes       0.97      0.97      0.97        37\n",
      "              Edible Grocery       0.78      0.76      0.77       181\n",
      "         Fluid Milk Products       0.83      0.83      0.83         6\n",
      "                 Foodservice       0.87      0.87      0.87        15\n",
      "  Frozen Dispensed Beverages       1.00      0.67      0.80         3\n",
      "                Frozen Foods       1.00      1.00      1.00         1\n",
      "         General Merchandise       0.87      0.84      0.86       127\n",
      "           Health and Beauty       0.96      0.85      0.90       109\n",
      "     Hot Dispensed Beverages       0.50      1.00      0.67         1\n",
      "                         Ice       1.00      1.00      1.00         1\n",
      "                   Motor Oil       0.94      1.00      0.97        16\n",
      "    Non-edible Grocery NoTax       0.81      0.61      0.69        28\n",
      "          Other Dairy - Deli       1.00      0.33      0.50        12\n",
      "               Other Tobacco       0.93      0.98      0.96       189\n",
      "          Packaged Beverages       0.92      0.99      0.95       230\n",
      "Packaged Ice Cream Novelties       1.00      0.75      0.86         8\n",
      "       Packaged Sweet Snacks       0.86      0.86      0.86        96\n",
      "          Perishable Grocery       0.50      0.60      0.55         5\n",
      "                Publications       0.67      1.00      0.80         2\n",
      "                Salty Snacks       0.92      0.95      0.94       224\n",
      "                        Wine       1.00      0.89      0.94        18\n",
      "\n",
      "                    accuracy                           0.92      2013\n",
      "                   macro avg       0.90      0.87      0.87      2013\n",
      "                weighted avg       0.92      0.92      0.92      2013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "          Alternative Snacks       0.83      0.89      0.86        73\n",
      "         Automotive Products       0.53      0.42      0.47        19\n",
      "                        Beer       0.93      0.87      0.90       160\n",
      "                       Candy       0.75      0.90      0.82       337\n",
      "                  Cigarettes       0.96      0.99      0.97        75\n",
      "    Cold Dispensed Beverages       1.00      0.75      0.86         4\n",
      "       Commissary - Packaged       0.94      0.81      0.87        36\n",
      "                E-Cigarettes       0.89      0.86      0.88        37\n",
      "              Edible Grocery       0.66      0.59      0.63       181\n",
      "         Fluid Milk Products       0.40      0.33      0.36         6\n",
      "                 Foodservice       0.50      0.60      0.55        15\n",
      "  Frozen Dispensed Beverages       1.00      0.67      0.80         3\n",
      "                Frozen Foods       0.50      1.00      0.67         1\n",
      "         General Merchandise       0.79      0.69      0.74       127\n",
      "           Health and Beauty       0.76      0.68      0.72       109\n",
      "     Hot Dispensed Beverages       0.00      0.00      0.00         1\n",
      "                         Ice       0.00      0.00      0.00         1\n",
      "                   Motor Oil       0.93      0.88      0.90        16\n",
      "    Non-edible Grocery NoTax       0.69      0.39      0.50        28\n",
      "          Other Dairy - Deli       0.80      0.33      0.47        12\n",
      "               Other Tobacco       0.92      0.93      0.92       189\n",
      "          Packaged Beverages       0.82      0.84      0.83       230\n",
      "Packaged Ice Cream Novelties       0.67      0.75      0.71         8\n",
      "       Packaged Sweet Snacks       0.77      0.71      0.74        96\n",
      "          Perishable Grocery       0.75      0.60      0.67         5\n",
      "                Publications       0.67      1.00      0.80         2\n",
      "                Salty Snacks       0.86      0.91      0.88       224\n",
      "                        Wine       0.86      0.67      0.75        18\n",
      "\n",
      "                    accuracy                           0.81      2013\n",
      "                   macro avg       0.72      0.68      0.69      2013\n",
      "                weighted avg       0.81      0.81      0.81      2013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmr\\.conda\\envs\\class\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', tree.DecisionTreeClassifier()),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "          Alternative Snacks       0.87      0.93      0.90        73\n",
      "         Automotive Products       0.91      0.53      0.67        19\n",
      "                        Beer       0.94      0.94      0.94       160\n",
      "                       Candy       0.78      0.97      0.86       337\n",
      "                  Cigarettes       1.00      1.00      1.00        75\n",
      "    Cold Dispensed Beverages       1.00      0.50      0.67         4\n",
      "       Commissary - Packaged       1.00      0.72      0.84        36\n",
      "                E-Cigarettes       0.94      0.92      0.93        37\n",
      "              Edible Grocery       0.74      0.62      0.67       181\n",
      "         Fluid Milk Products       0.56      0.83      0.67         6\n",
      "                 Foodservice       0.77      0.67      0.71        15\n",
      "  Frozen Dispensed Beverages       1.00      0.67      0.80         3\n",
      "                Frozen Foods       1.00      1.00      1.00         1\n",
      "         General Merchandise       0.85      0.74      0.79       127\n",
      "           Health and Beauty       0.90      0.73      0.81       109\n",
      "     Hot Dispensed Beverages       0.00      0.00      0.00         1\n",
      "                         Ice       1.00      1.00      1.00         1\n",
      "                   Motor Oil       0.94      0.94      0.94        16\n",
      "    Non-edible Grocery NoTax       0.76      0.46      0.58        28\n",
      "          Other Dairy - Deli       1.00      0.08      0.15        12\n",
      "               Other Tobacco       0.93      0.98      0.96       189\n",
      "          Packaged Beverages       0.90      0.92      0.91       230\n",
      "Packaged Ice Cream Novelties       1.00      0.62      0.77         8\n",
      "       Packaged Sweet Snacks       0.82      0.77      0.80        96\n",
      "          Perishable Grocery       0.50      0.40      0.44         5\n",
      "                Publications       0.67      1.00      0.80         2\n",
      "                Salty Snacks       0.84      0.92      0.88       224\n",
      "                        Wine       0.93      0.72      0.81        18\n",
      "\n",
      "                    accuracy                           0.86      2013\n",
      "                   macro avg       0.84      0.74      0.76      2013\n",
      "                weighted avg       0.86      0.86      0.85      2013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                     ])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep Neural Networks</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import  Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(X_train, X_test,MAX_NB_WORDS=75000):\n",
    "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS)\n",
    "    X_train = vectorizer_x.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer_x.transform(X_test).toarray()\n",
    "    print(\"tf-idf with\",str(np.array(X_train).shape[1]),\"features\")\n",
    "    return (X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare target\n",
    "def prepare_targets_le(y_train, y_test):\n",
    "    # need to make sure we force a 2D array or we'll run into trouble with LE\n",
    "    y_train = y_train.to_numpy().reshape(-1,1)\n",
    "    y_test = y_test.to_numpy().reshape(-1,1)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare target\n",
    "def prepare_targets_oe(y_train, y_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(y_train)\n",
    "    y_train_enc = oe.transform(y_train)\n",
    "    y_test_enc = oe.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model_DNN_Text(shape, nClasses, dropout=0.5):\n",
    "    \"\"\"\n",
    "    buildModel_DNN_Tex(shape, nClasses,dropout)\n",
    "    Build Deep neural networks Model for text classification\n",
    "    Shape is input feature space\n",
    "    nClasses is number of classes\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    node = 2500 # number of nodes\n",
    "    nLayers = 1 # number of  hidden layer\n",
    "\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,nLayers):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sku['Category'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#y_train = y_train.values.reshape(-1,1)\n",
    "#y_test = y_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 5125 features\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf,X_test_tfidf = TFIDF(X_train,X_test)\n",
    "y_train_enc, y_test_enc = prepare_targets_oe(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc = y_test_enc.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc = y_test_enc.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 29)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for i in y_test_enc ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predicted,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        73\n",
      "           1       0.79      0.79      0.79        19\n",
      "           2       0.97      0.96      0.97       160\n",
      "           3       0.97      0.95      0.96       337\n",
      "           4       1.00      1.00      1.00        75\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       0.97      0.92      0.94        36\n",
      "           7       0.97      0.97      0.97        37\n",
      "           8       0.76      0.77      0.77       181\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       0.70      0.93      0.80        15\n",
      "          11       1.00      0.67      0.80         3\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       0.84      0.88      0.86       127\n",
      "          14       0.97      0.83      0.90       109\n",
      "          15       0.20      1.00      0.33         1\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       1.00      0.88      0.93        16\n",
      "          18       0.89      0.57      0.70        28\n",
      "          19       1.00      0.50      0.67        12\n",
      "          20       0.95      0.98      0.97       189\n",
      "          21       0.92      0.98      0.95       230\n",
      "          23       1.00      0.75      0.86         8\n",
      "          24       0.86      0.83      0.85        96\n",
      "          25       0.50      0.40      0.44         5\n",
      "          26       0.20      1.00      0.33         2\n",
      "          27       0.92      0.94      0.93       224\n",
      "          28       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.91      2013\n",
      "   macro avg       0.87      0.87      0.84      2013\n",
      "weighted avg       0.92      0.91      0.91      2013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model_DNN.predict(X_test_tfidf)\n",
    "\n",
    "print(metrics.classification_report(y_test_enc, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf with 5125 features\n",
      "Train on 8052 samples, validate on 2013 samples\n",
      "Epoch 1/10\n",
      "8052/8052 - 12s - loss: 1.8317 - accuracy: 0.5067 - val_loss: 0.7619 - val_accuracy: 0.8058\n",
      "Epoch 2/10\n",
      "8052/8052 - 11s - loss: 0.4581 - accuracy: 0.8884 - val_loss: 0.4500 - val_accuracy: 0.8917\n",
      "Epoch 3/10\n",
      "8052/8052 - 11s - loss: 0.1756 - accuracy: 0.9540 - val_loss: 0.4221 - val_accuracy: 0.9016\n",
      "Epoch 4/10\n",
      "8052/8052 - 11s - loss: 0.0840 - accuracy: 0.9778 - val_loss: 0.4399 - val_accuracy: 0.9046\n",
      "Epoch 5/10\n",
      "8052/8052 - 12s - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.4608 - val_accuracy: 0.9021\n",
      "Epoch 6/10\n",
      "8052/8052 - 12s - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.4708 - val_accuracy: 0.9061\n",
      "Epoch 7/10\n",
      "8052/8052 - 11s - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.4821 - val_accuracy: 0.9021\n",
      "Epoch 8/10\n",
      "8052/8052 - 12s - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.4818 - val_accuracy: 0.9066\n",
      "Epoch 9/10\n",
      "8052/8052 - 12s - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.5191 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "8052/8052 - 12s - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.5053 - val_accuracy: 0.9016\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-a6510aa764cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_DNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\rmr\\.conda\\envs\\class\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1850\u001b[0m     \"\"\"\n\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rmr\\.conda\\envs\\class\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "X_train_tfidf,X_test_tfidf = TFIDF(X_train,X_test)\n",
    "y_train_enc, y_test_enc = prepare_targets_oe(y_train, y_test)\n",
    "model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1], 29) # 29 is df_sku['Category'].nunique()\n",
    "model_DNN.fit(X_train_tfidf, y_train_enc,\n",
    "                              validation_data=(X_test_tfidf, y_test_enc),\n",
    "                              epochs=10,\n",
    "                              batch_size=128,\n",
    "                              verbose=2)\n",
    "\n",
    "predicted = model_DNN.predict(X_test_tfidf)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train)\n",
    "    X_train_enc = oe.transform(X_train)\n",
    "    X_test_enc = oe.transform(X_test)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['HALLS C DROP ICE BL(ICE PEP)' 'BIC UGLY SWEATERS SE'\n 'BRUTON 6 OZ PLS GLASS' ... 'LAYS POTATO CHIP SALT AND VINEGAR'\n 'KETTLE THICK&BOLD BBQ CHP' 'MCCORMICK BLACK PEPPER 1.5Z'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-15c5e05a343e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# prepare input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# prepare output data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-108-f063f9a55c5a>\u001b[0m in \u001b[0;36mprepare_inputs\u001b[1;34m(X_train, X_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0moe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0moe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mX_train_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_test_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'iloc'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# if not a dataframe, do normal check_array validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             if (not hasattr(X, 'dtype')\n\u001b[0;32m     45\u001b[0m                     and np.issubdtype(X_temp.dtype, np.str_)):\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['HALLS C DROP ICE BL(ICE PEP)' 'BIC UGLY SWEATERS SE'\n 'BRUTON 6 OZ PLS GLASS' ... 'LAYS POTATO CHIP SALT AND VINEGAR'\n 'KETTLE THICK&BOLD BBQ CHP' 'MCCORMICK BLACK PEPPER 1.5Z'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train_enc.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_enc, y_train_enc, epochs=100, batch_size=16, verbose=2)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
